<!doctype html>
<html>

<head>

  <title>
    
      Anatomy of Natural Language Processing | Mahesh Kumar
    
  </title>

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta charset="utf-8">

  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="stylesheet" href="/assets/css/syntax.css">
  <!-- Use Atom -->
  <link type="application/atom+xml" rel="alternate" href="http://localhost:4000/rss-feed.xml" title="Mahesh Kumar" />
  <!-- Use RSS-2.0 -->
  <!--<link href="/rss-feed.xml" type="application/rss+xml" rel="alternate" title="Mahesh Kumar | "/>
  //-->

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Code+Pro">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Quattrocento+Sans">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

  <script type="text/javascript" async
    src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>

  <!-- Google Analytics -->
  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-82492711-1', 'auto');
  ga('send', 'pageview');
</script>


  <!-- Use Jekyll SEO plugin -->
  <!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Anatomy of Natural Language Processing | Mahesh Kumar</title>
<meta name="generator" content="Jekyll v3.6.2" />
<meta property="og:title" content="Anatomy of Natural Language Processing" />
<meta name="author" content="Mahesh Kumar K" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Source: https://people.cs.umass.edu/~sameer/" />
<meta property="og:description" content="Source: https://people.cs.umass.edu/~sameer/" />
<link rel="canonical" href="http://localhost:4000/article/anatomy-of-natural-language-processing.html" />
<meta property="og:url" content="http://localhost:4000/article/anatomy-of-natural-language-processing.html" />
<meta property="og:site_name" content="Mahesh Kumar" />
<meta property="og:image" content="http://localhost:4000/nlp.jpg" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2017-03-13T06:17:14-05:00" />
<script type="application/ld+json">
{"description":"Source: https://people.cs.umass.edu/~sameer/","author":{"@type":"Person","name":"Mahesh Kumar K"},"@type":"BlogPosting","url":"http://localhost:4000/article/anatomy-of-natural-language-processing.html","image":"http://localhost:4000/nlp.jpg","headline":"Anatomy of Natural Language Processing","dateModified":"2017-03-13T06:17:14-05:00","datePublished":"2017-03-13T06:17:14-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/article/anatomy-of-natural-language-processing.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


</head>


<body>

  <div class="container">
    <header class="masthead">
  <h3 class="masthead-title">
    <a href="/">Mahesh Kumar</a>
    <!-- <small class="masthead-subtitle"></small> -->
    <div class="menu">
  <nav class="menu-content">
    
      <a href="/menu/about.html">About</a>
    
  </nav>
  <nav class="social-icons">
    
  
  
    <a href="https://www.github.com/maheshkkumar" target="_blank"><i class="fa fa-github" aria-hidden="true"></i></a>
  

  
  
    <a href="https://twitter.com/maheshkumark_" target="_blank"><i class="fa fa-twitter" aria-hidden="true"></i></a>
  

  
  
    <a href="https://www.linkedin.com/in/maheshkumark" target="_blank"><i class="fa fa-linkedin" aria-hidden="true"></i></a>
  

  
  
    <a href="mailto:maheshk2194@gmail.com" target="_blank"><i class="fa fa-envelope" aria-hidden="true"></i></a>
  

  
  
    <a href="/rss-feed.xml"><i class="fa fa-rss-square" aria-hidden="true"></i></a>
  

  </nav>
</div>

  </h3>
</header>


    <div class="post-container">
      <h1>
  Anatomy of Natural Language Processing
</h1>


  <img src="/assets/img/nlp.jpg">


<p><em>Source: <a href="https://people.cs.umass.edu/~sameer/">https://people.cs.umass.edu/~sameer/</a></em></p>

<p>As Wikipedia says ‘Natural language processing (NLP) is a field of computer science, artificial intelligence, and computational linguistics concerned with the interactions between computers and human (natural) languages and, in particular, concerned with programming computers to fruitfully process large natural language corpora’.</p>

<h3 id="why-is-nlp-required">Why is NLP required?</h3>

<p>There are several reasons that made NLP popular within the Artificial Intelligence and Machine Learning community, especially the huge opportunity that NLP provided to everyone to work on large sets of textual data.</p>

<p>Few of the domains, where NLP plays a crucial role is:</p>

<ul>
  <li>Auto Summarization</li>
  <li>Chatbots</li>
  <li>Machine Translation</li>
  <li>Text Classification</li>
  <li>Sentimental Analysis</li>
  <li>Speech Recognition</li>
</ul>

<h3 id="steps-taken-to-solve-a-nlp-problem">Steps taken to solve a NLP problem</h3>

<p>In this notebook, let’s try to classify news’s articles to different categories based on the article content and in doing so let’s look at the various steps that we take to solve a NLP problem.</p>

<h4 id="1-collection-of-the-dataset">1. Collection of the Dataset</h4>

<p>The first and foremost step in any Machine Learning or NLP based problem is to collect a dataset. For our problem, let’s try to collect news articles from <a href="http://www.doxydonkey.blogspot.in">Doxydonkey</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># imports</span>
<span class="kn">import</span> <span class="nn">urllib2</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># URL to collect the data</span>
<span class="n">url</span> <span class="o">=</span> <span class="s">"http://doxydonkey.blogspot.in"</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Method to request, response and soup the data</span>
<span class="k">def</span> <span class="nf">beautifySoup</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>
    <span class="n">request</span> <span class="o">=</span> <span class="n">urllib2</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">urllib2</span><span class="o">.</span><span class="n">urlopen</span><span class="p">(</span><span class="n">request</span><span class="p">)</span>
    <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">soup</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Collecting all articles hyper links</span>
<span class="k">def</span> <span class="nf">collectArticles</span><span class="p">(</span><span class="n">links</span><span class="p">):</span>
    <span class="n">articles</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">link</span> <span class="ow">in</span> <span class="n">links</span><span class="p">:</span>
        <span class="n">content</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">soup</span> <span class="o">=</span> <span class="n">beautifySoup</span><span class="p">(</span><span class="n">link</span><span class="p">)</span>
        <span class="n">divs</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s">'div'</span><span class="p">,</span> <span class="p">{</span><span class="s">'class'</span><span class="p">:</span> <span class="s">'post-body'</span><span class="p">})</span>
        <span class="k">for</span> <span class="n">div</span> <span class="ow">in</span> <span class="n">divs</span><span class="p">:</span>
            <span class="n">content</span> <span class="o">+=</span> <span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">p</span><span class="p">:</span> <span class="n">p</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s">"ascii"</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s">"replace"</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s">"?"</span><span class="p">,</span> <span class="s">""</span><span class="p">),</span> <span class="n">div</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s">"li"</span><span class="p">))</span>
        <span class="n">articles</span> <span class="o">+=</span> <span class="n">content</span>
    <span class="k">return</span> <span class="n">articles</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Method to collect all the articles data</span>
<span class="k">def</span> <span class="nf">collectData</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">links</span><span class="p">):</span>
    <span class="n">soup</span> <span class="o">=</span> <span class="n">beautifySoup</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">soup</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s">"a"</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">title</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="s">"title"</span><span class="p">]</span>
            <span class="n">url</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="s">"href"</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">title</span> <span class="o">==</span> <span class="s">"Older Posts"</span><span class="p">:</span>
                <span class="n">links</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
                <span class="n">collectData</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">links</span><span class="p">)</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="n">url</span> <span class="o">=</span> <span class="s">""</span>
    <span class="k">return</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># global list that stores all the article hyper links</span>
<span class="n">links</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">def</span> <span class="nf">collectParameters</span><span class="p">():</span>
    <span class="n">links</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
    <span class="n">collectData</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">links</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">links</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># calling the parameters method </span>
<span class="n">collectParameters</span><span class="p">()</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>80
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># articles list stores all the content</span>
<span class="n">articles</span> <span class="o">=</span> <span class="n">collectArticles</span><span class="p">(</span><span class="n">links</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">articles</span><span class="p">))</span>
<span class="n">articles</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2673





'Airbnb raises $1 billion inlatestround of funding:Onlineroom rentingservice Airbnb Inc said on Thursday it had raised $1 billion in its latest round of funding, valuing the company at $31 billion.The company turned in a profit on an EBITDA basis in the second half of 2016 and expects to continue to be profitable this year, the source said, adding that Airbnb had no plans to go public anytime soon.The company is locked in an intensifying global battle with regulators who say the service takesaffordablehousing off the market and drives up rental prices.Airbnb raised $447.85 million as part of the funding, a source close to the company told Reuters. The company said in September it had raised about $555 million as part of the same round of funding.Airbnb, which operates in more than 65,000 cities, has enjoyed tremendous growth as it pushes ahead with its plansofglobal expansion.'
</code></pre></div></div>

<h4 id="2-term-frequency---inverse-document-frequency">2. Term Frequency - Inverse Document Frequency</h4>

<p>TF-IDF weight is often used in information retrieval and text mining. The weight is a statistical measure used to evaluate how important a word is to a document in a collection or corpus.</p>

<p>TF-IDF is made up of two components:</p>
<ul>
  <li>
    <p>TF - Term Frequency</p>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  Term Frequency is the measure of how frequently a word appears in a document.
  TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document)
</code></pre></div>    </div>
  </li>
  <li>
    <p>IDF - Inverse Document Frequency
      Inverse Document Frequency the measure of how important a term is.
      IDF(t) = log_e(Total number of documents / Number of documents with term t in it)</p>
  </li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># importing feature extractor TF-IDF vectorizer</span>

<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfVectorizer</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># instantiating tfidf vectorizer</span>
<span class="n">vectorizer</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">(</span><span class="n">max_df</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">min_df</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stop_words</span><span class="o">=</span><span class="s">"english"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Applying tf-idf transformation on the articles </span>
<span class="n">articles_tfidf</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">articles</span><span class="p">)</span>

<span class="c"># Let's see the tf-idf for the first article</span>
<span class="k">print</span><span class="p">(</span><span class="n">articles_tfidf</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  (0, 4527)	0.093459986294
  (0, 880)	0.0909888475678
  (0, 9245)	0.125506358268
  (0, 5484)	0.0593929321553
  (0, 12111)	0.136331194112
  (0, 4293)	0.136331194112
  (0, 2522)	0.0853580208378
  (0, 1)	0.065168725165
  (0, 470)	0.109464227828
  (0, 8136)	0.103883585377
  (0, 427)	0.158782106766
  (0, 10394)	0.0896669240819
  (0, 9883)	0.0904124688247
  (0, 11941)	0.0768705699236
  (0, 2603)	0.0766677306981
  (0, 7515)	0.0847935427048
  (0, 539)	0.113991816532
  (0, 363)	0.169920689887
  (0, 8980)	0.0869161877993
  (0, 9696)	0.121217078597
  (0, 4015)	0.123688217323
  (0, 7265)	0.0517256017034
  (0, 10412)	0.0532921082588
  (0, 10199)	0.0728780620055
  (0, 9604)	0.100322272811
  :	:
  (0, 9194)	0.0657727820619
  (0, 8711)	0.0676923544855
  (0, 735)	0.0880771876065
  (0, 10875)	0.177538939725
  (0, 13072)	0.0378691826488
  (0, 9066)	0.0955164362715
  (0, 2980)	0.0875720285004
  (0, 4534)	0.102520325273
  (0, 180)	0.0853580208378
  (0, 5550)	0.0794643241154
  (0, 10304)	0.0705467582402
  (0, 1598)	0.100928007859
  (0, 4101)	0.133419534151
  (0, 9064)	0.0717214619913
  (0, 12206)	0.0983256447076
  (0, 277)	0.0884205814672
  (0, 12531)	0.120451910281
  (0, 10049)	0.14874067677
  (0, 6779)	0.0767689144505
  (0, 9353)	0.213261264741
  (0, 11862)	0.0730484148993
  (0, 5171)	0.298211234269
  (0, 1741)	0.127885890416
  (0, 9354)	0.0950423945693
  (0, 892)	0.545073115219
</code></pre></div></div>

<h4 id="3-clustering-the-articles">3. Clustering the articles</h4>

<p>Next, let’s cluster the above articles in order to predict the category of future articles.</p>

<p>Let’s use KMeans algorithm to cluster the articles.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># importing KMeans algorithm from sklearn</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># instance of KMeans</span>
<span class="n">km</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s">'k-means++'</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># fitting the model with the articles dataset</span>
<span class="n">km</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">articles_tfidf</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Initialization complete
Iteration  0, inertia 4766.061
Iteration  1, inertia 2505.458
Iteration  2, inertia 2486.992
Iteration  3, inertia 2472.086
Iteration  4, inertia 2466.478
Iteration  5, inertia 2463.909
Iteration  6, inertia 2461.882
Iteration  7, inertia 2459.012
Iteration  8, inertia 2454.963
Iteration  9, inertia 2452.054
Iteration 10, inertia 2451.220
Iteration 11, inertia 2450.913
Iteration 12, inertia 2450.580
Iteration 13, inertia 2450.332
Iteration 14, inertia 2450.119
Iteration 15, inertia 2449.953
Iteration 16, inertia 2449.779
Iteration 17, inertia 2449.599
Iteration 18, inertia 2449.449
Iteration 19, inertia 2449.363
Iteration 20, inertia 2449.310
Iteration 21, inertia 2449.259
Iteration 22, inertia 2449.234
Iteration 23, inertia 2449.201
Iteration 24, inertia 2449.181
Iteration 25, inertia 2449.172
Converged at iteration 25
Initialization complete
Iteration  0, inertia 4720.011
Iteration  1, inertia 2477.708
Iteration  2, inertia 2462.645
Iteration  3, inertia 2456.979
Iteration  4, inertia 2454.321
Iteration  5, inertia 2453.198
Iteration  6, inertia 2452.395
Iteration  7, inertia 2451.989
Iteration  8, inertia 2451.752
Iteration  9, inertia 2451.645
Iteration 10, inertia 2451.604
Iteration 11, inertia 2451.591
Converged at iteration 11





KMeans(copy_x=True, init='k-means++', max_iter=100, n_clusters=10, n_init=2,
    n_jobs=1, precompute_distances='auto', random_state=None, tol=0.0001,
    verbose=True)
</code></pre></div></div>

<p>So, we have fitted the algorithm with the dataset. Now, let’s check the type of articles that are clustered.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Label that is assigned to each articles </span>
<span class="k">print</span><span class="p">(</span><span class="s">"Label of each article: {}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">km</span><span class="o">.</span><span class="n">labels_</span><span class="p">))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Label of each article: [1 7 2 ..., 0 0 1]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Total number of articles in each cluster</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">cluster_count</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">km</span><span class="o">.</span><span class="n">labels_</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Number of articles in each cluster: {}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cluster_count</span><span class="p">))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Number of articles in each cluster: (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), array([730, 377, 326, 148,  36, 295, 168, 168, 244, 181], dtype=int64))
</code></pre></div></div>

<p>Now, let’s segregate the articles into their respective clusters.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Segregating the documents according to the clusters</span>

<span class="n">article_clusters</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">cluster</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">km</span><span class="o">.</span><span class="n">labels_</span><span class="p">):</span>
    <span class="n">document</span> <span class="o">=</span> <span class="n">articles</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">cluster</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">article_clusters</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="n">article_clusters</span><span class="p">[</span><span class="n">cluster</span><span class="p">]</span> <span class="o">=</span> <span class="n">document</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">article_clusters</span><span class="p">[</span><span class="n">cluster</span><span class="p">]</span> <span class="o">+=</span> <span class="n">document</span>
</code></pre></div></div>

<h4 id="4-tokenizing-the-collected-data">4. Tokenizing the collected data</h4>

<p>The step in the process is to tokenize the collected data. What do you mean by tokenizing the data?</p>

<p>Tokenization is the process of breaking down the complex sentences to individual words.</p>

<blockquote>
  <p>“I like dogs”</p>
</blockquote>

<p>So, the above statement can be tokenized to get (“I”, “like”, “dogs”), this is similar to using <strong>split()</strong> method to tokenize a sentence.</p>

<p>In terms of NLP, tokens better known as <strong>n-grams</strong>, where one word is called <strong>unigram</strong>, 2 words are called as <strong>bigram</strong> and multiple words are called a <strong>n-grams</strong>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># import statements</span>

<span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">stopwords</span>
<span class="kn">from</span> <span class="nn">nltk.tokenize</span> <span class="kn">import</span> <span class="n">word_tokenize</span><span class="p">,</span> <span class="n">sent_tokenize</span>
<span class="kn">from</span> <span class="nn">nltk.probability</span> <span class="kn">import</span> <span class="n">FreqDist</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>
<span class="kn">from</span> <span class="nn">string</span> <span class="kn">import</span> <span class="n">punctuation</span>
<span class="kn">from</span> <span class="nn">heapq</span> <span class="kn">import</span> <span class="n">nlargest</span>
<span class="kn">import</span> <span class="nn">nltk</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Let's declare a list of some not so important words that might appear in the articles</span>

<span class="n">special_words</span> <span class="o">=</span> <span class="p">[</span><span class="s">"billion"</span><span class="p">,</span> <span class="s">"million"</span><span class="p">,</span> <span class="s">"billions"</span><span class="p">,</span> <span class="s">"millions"</span><span class="p">,</span> <span class="s">"$"</span><span class="p">,</span>  <span class="s">"'s"</span><span class="p">,</span> <span class="s">"'d"</span><span class="p">,</span> <span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="s">"</span><span class="se">\t</span><span class="s">"</span><span class="p">,</span> <span class="s">"''"</span><span class="p">,</span> <span class="s">"``"</span><span class="p">,</span> <span class="s">"`"</span><span class="p">,</span> <span class="s">"*"</span><span class="p">]</span>
<span class="n">stop_words</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s">"english"</span><span class="p">)))</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">punctuation</span><span class="p">)</span> <span class="o">+</span> <span class="n">special_words</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Stop words are: {}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">stop_words</span><span class="p">))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Stop words are: [u'all', u'just', u'being', u'over', u'both', u'through', u'yourselves', u'its', u'before', u'o', u'hadn', u'herself', u'll', u'had', u'should', u'to', u'only', u'won', u'under', u'ours', u'has', u'do', u'them', u'his', u'very', u'they', u'not', u'during', u'now', u'him', u'nor', u'd', u'did', u'didn', u'this', u'she', u'each', u'further', u'where', u'few', u'because', u'doing', u'some', u'hasn', u'are', u'our', u'ourselves', u'out', u'what', u'for', u'while', u're', u'does', u'above', u'between', u'mustn', u't', u'be', u'we', u'who', u'were', u'here', u'shouldn', u'hers', u'by', u'on', u'about', u'couldn', u'of', u'against', u's', u'isn', u'or', u'own', u'into', u'yourself', u'down', u'mightn', u'wasn', u'your', u'from', u'her', u'their', u'aren', u'there', u'been', u'whom', u'too', u'wouldn', u'themselves', u'weren', u'was', u'until', u'more', u'himself', u'that', u'but', u'don', u'with', u'than', u'those', u'he', u'me', u'myself', u'ma', u'these', u'up', u'will', u'below', u'ain', u'can', u'theirs', u'my', u'and', u've', u'then', u'is', u'am', u'it', u'doesn', u'an', u'as', u'itself', u'at', u'have', u'in', u'any', u'if', u'again', u'no', u'when', u'same', u'how', u'other', u'which', u'you', u'shan', u'needn', u'haven', u'after', u'most', u'such', u'why', u'a', u'off', u'i', u'm', u'yours', u'so', u'y', u'the', u'having', u'once', '!', '"', '#', '$', '%', '&amp;', "'", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '&lt;', '=', '&gt;', '?', '@', '[', '\\', ']', '^', '_', '`', '{', '|', '}', '~', 'billion', 'million', 'billions', 'millions', '$', "'s", "'d", '\n', '\t', "''", '``', '`', '*']
</code></pre></div></div>

<p>In the next step, we will see the top words from each cluster, this should give us an idea of theme of each cluster.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">keywords</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">counts</span> <span class="o">=</span> <span class="p">{}</span>

<span class="k">for</span> <span class="n">cluster</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">km</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">):</span>
    <span class="n">word_set</span> <span class="o">=</span> <span class="n">word_tokenize</span><span class="p">(</span><span class="n">article_clusters</span><span class="p">[</span><span class="n">cluster</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
    <span class="n">word_set</span> <span class="o">=</span> <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">word_set</span> <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stop_words</span> <span class="ow">and</span> <span class="n">word</span> <span class="o">!=</span> <span class="s">""</span><span class="p">]</span>
    <span class="n">freq_distribution</span> <span class="o">=</span> <span class="n">FreqDist</span><span class="p">(</span><span class="n">word_set</span><span class="p">)</span>
    <span class="n">keywords</span><span class="p">[</span><span class="n">cluster</span><span class="p">]</span> <span class="o">=</span> <span class="n">nlargest</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">freq_distribution</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">freq_distribution</span><span class="o">.</span><span class="n">get</span><span class="p">)</span>
    <span class="n">counts</span><span class="p">[</span><span class="n">cluster</span><span class="p">]</span> <span class="o">=</span> <span class="n">freq_distribution</span>

<span class="c"># printing the top 100 words from each cluster</span>
<span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">keywords</span><span class="o">.</span><span class="n">iteritems</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">[:</span><span class="mi">20</span><span class="p">])</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(0, ['google', 'company', 'said', 'new', 'app', 'like', 'mobile', 'users', 'also', 'one', 'people', 'service', 'companies', 'online', 'year', 'would', 'search', 'technology', 'percent', 'last'])
(1, ['company', 'said', 'investors', 'year', 'companies', 'new', 'last', 'india', 'round', 'funding', 'capital', 'raised', 'also', 'venture', 'like', 'one', 'valuation', 'online', 'firm', 'investment'])
(2, ['percent', 'company', 'alibaba', 'said', 'year', 'shares', 'market', 'china', 'sales', 'stock', 'new', 'growth', 'last', 'revenue', 'online', 'chinese', 'investors', 'companies', 'according', 'e-commerce'])
(3, ['uber', 'company', 'said', 'lyft', 'drivers', 'service', 'china', 'didi', 'new', 'ride-hailing', 'people', 'also', 'ubers', 'investors', 'companies', 'according', 'would', 'rides', 'app', 'year'])
(4, ['version', 'mp3', 'snippethereis', 'anaudio', 'snippet', 'thissnippet', 'thissnippet.hereis', 'audio', 'snippethere', 'archivedsnippetsarehere.hereis', 'thissnippethereis', 'snippet.hereis', 'soundcloudhereis', 'experimental.hereis', 'herehereis', 'mp3hereis', 'soundcloud.hereis', 'experimentalhereis', 'soundcloudanmp3version', 'experimental'])
(5, ['facebook', 'twitter', 'users', 'ads', 'company', 'new', 'said', 'video', 'people', 'ad', 'social', 'like', 'app', 'also', 'percent', 'mobile', 'snapchat', 'instagram', 'advertisers', 'data'])
(6, ['apple', 'said', 'iphone', 'company', 'percent', 'pay', 'sales', 'new', 'watch', 'china', 'year', 'apples', 'also', 'market', 'app', 'mobile', 'according', 'first', 'would', 'quarter'])
(7, ['amazon', 'said', 'company', 'new', 'service', 'prime', 'online', 'percent', 'delivery', 'services', 'customers', 'amazons', 'also', 'year', 'business', 'products', 'items', 'sales', 'last', 'like'])
(8, ['said', 'company', 'data', 'companies', 'microsoft', 'software', 'business', 'new', 'cloud', 'percent', 'year', 'technology', 'also', 'would', 'tesla', 'cars', 'like', 'google', 'car', 'last'])
(9, ['percent', 'revenue', 'company', 'quarter', 'year', 'said', 'share', 'shares', 'rose', 'cents', 'profit', 'business', 'analysts', 'sales', 'net', 'per', 'earnings', 'growth', 'reported', 'forecast'])
</code></pre></div></div>

<p>Here, let’s find the unique words in each cluster</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">unique_words</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">cluster</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">km</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">):</span>
    <span class="n">temp_cluster_1</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">km</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">))</span> <span class="o">-</span> <span class="nb">set</span><span class="p">([</span><span class="n">cluster</span><span class="p">]))</span>
    <span class="n">temp_cluster_2</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">keywords</span><span class="p">[</span><span class="n">temp_cluster_1</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">keywords</span><span class="p">[</span><span class="n">temp_cluster_1</span><span class="p">[</span><span class="mi">1</span><span class="p">]]))</span>
    <span class="n">unique_word</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">keywords</span><span class="p">[</span><span class="n">cluster</span><span class="p">])</span> <span class="o">-</span> <span class="n">temp_cluster_2</span>
    <span class="n">unique_words</span><span class="p">[</span><span class="n">cluster</span><span class="p">]</span> <span class="o">=</span> <span class="n">nlargest</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">unique_word</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">counts</span><span class="p">[</span><span class="n">cluster</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># printing unique words to a cluster</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">words</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">unique_words</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">unique_words</span><span class="p">[</span><span class="n">words</span><span class="p">])</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(0, ['app', 'search', 'apps', 'use', 'video', 'product', 'facebook', 'way', 'products', 'content'])
(1, ['india', 'round', 'funding', 'capital', 'raised', 'venture', 'valuation', 'private', 'startup', 'rs'])
(2, ['alibaba', 'chinese', 'quarter', 'inc.', 'u.s.', 'share', 'biggest', 'stake', 'earnings', 'offering'])
(3, ['uber', 'lyft', 'drivers', 'didi', 'ride-hailing', 'ubers', 'rides', 'cities', 'kuaidi', 'driver'])
(4, ['version', 'mp3', 'snippethereis', 'anaudio', 'snippet', 'thissnippet', 'thissnippet.hereis', 'audio', 'archivedsnippetsarehere.hereis', 'snippethere'])
(5, ['twitter', 'snapchat', 'instagram', 'advertisers', 'news', 'advertising', 'brands', 'user', 'facebooks', 'feature'])
(6, ['apple', 'iphone', 'watch', 'apples', 'quarter', 'iphones', 'smartphone', 'samsung', 'u.s.', 'payments'])
(7, ['prime', 'amazons', 'items', 'amazon.com', 'shipping', 'sellers', 'retailer', 'shoppers', 'customer', 'jet'])
(8, ['microsoft', 'cloud', 'tesla', 'cars', 'car', 'model', 'computing', 'vehicles', 'executive', 'systems'])
(9, ['quarter', 'share', 'rose', 'cents', 'profit', 'analysts', 'net', 'earnings', 'reported', 'forecast'])
</code></pre></div></div>

<p>By now, we know what’s the theme of each cluster</p>

<ul>
  <li>Cluster 0 - Apps</li>
  <li>Cluster 1 - Funding</li>
  <li>Cluster 2 - Company Earnings</li>
  <li>Cluster 3 - Car Transportation</li>
  <li>Cluster 4 - Music (Looks like an outlier)</li>
  <li>Cluster 5 - Social Media</li>
  <li>Cluster 6 - Phone</li>
  <li>Cluster 7 - Amazon</li>
  <li>Cluster 8 - Innovation</li>
  <li>Cluster 9 - Stocks</li>
</ul>

<p>Disclaimer - The clusters might not be accurately created, this is done just to give an overview on how the articles will be clustered.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">categories</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="s">"Apps"</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="s">"Funding"</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span> <span class="s">"Company Earnings"</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span> <span class="s">"Car Transportation"</span><span class="p">,</span> <span class="mi">4</span><span class="p">:</span> <span class="s">"Music"</span><span class="p">,</span> <span class="mi">5</span><span class="p">:</span> <span class="s">"Social Media"</span><span class="p">,</span> <span class="mi">6</span><span class="p">:</span> <span class="s">"Phone"</span><span class="p">,</span> <span class="mi">7</span><span class="p">:</span> <span class="s">"Amazon"</span><span class="p">,</span> <span class="mi">8</span><span class="p">:</span> <span class="s">"Innovation"</span><span class="p">,</span> <span class="mi">9</span><span class="p">:</span> <span class="s">"Stocks"</span><span class="p">}</span>
</code></pre></div></div>

<h4 id="5-predicting-the-label-for-an-article">5. Predicting the label for an article</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># We are using KNeighborsClassifier for predicting the class for an article</span>

<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Fitting the data to KNeighborsClassifier</span>

<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">articles_tfidf</span><span class="p">,</span> <span class="n">km</span><span class="o">.</span><span class="n">labels_</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights='uniform')
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">predict_airbnb</span> <span class="o">=</span> <span class="s">" Online room renting service Airbnb Inc said on Thursday it had raised $1 billion in its latest round of funding, valuing the company at $31 billion.The company turned in a profit on an EBITDA basis in the second half of 2016 and expects to continue to be profitable this year, the source said, adding that Airbnb had no plans to go public anytime soon. The company is locked in an intensifying global battle with regulators who say the service takes affordable housing off the market and drives up rental prices.Airbnb raised $447.85 million as part of the funding, a source close to the company told Reuters. The company said in September it had raised about $555 million as part of the same round of funding. Airbnb, which operates in more than 65,000 cities, has enjoyed tremendous growth as it pushes ahead with its plans of global expansion"</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">airbnb_transform</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">transform</span><span class="p">([</span><span class="n">predict_airbnb</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s">'utf8'</span><span class="p">)</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s">'ascii'</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s">'ignore'</span><span class="p">)])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">label</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">airbnb_transform</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

<span class="k">if</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">categories</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Category belongs to the category: {}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">categories</span><span class="p">[</span><span class="n">label</span><span class="p">]))</span>
<span class="k">else</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Unknown category"</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Article belongs to the category: Apps
</code></pre></div></div>

<p>Hope you understood the basics of a Natural Language Processing problem.</p>

<p>This basic introduction is based on <a href="https://www.pluralsight.com/courses/python-natural-language-processing">Swetha Kolalapudi</a>’s session.</p>


<span class="post-date">
  Written on
  
  March
  13th,
  2017
  by
  
    Mahesh Kumar K
  
</span>

<div class="post-date">Feel free to share!</div>
  <div class="sharing-icons">
    <a href="https://twitter.com/intent/tweet?text=Anatomy of Natural Language Processing&amp;url=/article/anatomy-of-natural-language-processing.html" target="_blank"><i class="fa fa-twitter" aria-hidden="true"></i></a>
    <a href="https://www.facebook.com/sharer/sharer.php?u=/article/anatomy-of-natural-language-processing.html&amp;title=Anatomy of Natural Language Processing" target="_blank"><i class="fa fa-facebook" aria-hidden="true"></i></a>
    <a href="https://plus.google.com/share?url=/article/anatomy-of-natural-language-processing.html" target="_blank"><i class="fa fa-google-plus" aria-hidden="true"></i></a>
  </div>
</div>


<div class="related">
  <h1 >You may also enjoy:</h1>
  
  <ul class="related-posts">
    
      
        
          <li>
            <h3>
              <a href="/article/a-guide-to-deploying-machine-learning-models-in-production.html">
                A guide to deploying Machine/Deep Learning model(s) in Production
                <!--<img src="http://localhost:4000/images/">-->
                <!--<small>June 25, 2018</small>-->
              </a>
            </h3>
          </li>
          
        
      
        
          <li>
            <h3>
              <a href="/article/multiclass-classification.html">
                Multiclass Classification
                <!--<img src="http://localhost:4000/images/">-->
                <!--<small>March 28, 2017</small>-->
              </a>
            </h3>
          </li>
          
        
      
        
        
      
    
      
        
        
      
    
  </ul>
</div>



  <section class="disqus">
  <div id="disqus_thread"></div>
  <script type="text/javascript">
    var disqus_shortname = "www-maheshkumar-xyz";
    var disqus_identifier = "/article/anatomy-of-natural-language-processing.html";
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>



    </div>

    <footer class="footer">
  
  
  
    <a href="https://www.github.com/maheshkkumar" target="_blank"><i class="fa fa-github" aria-hidden="true"></i></a>
  

  
  
    <a href="https://twitter.com/maheshkumark_" target="_blank"><i class="fa fa-twitter" aria-hidden="true"></i></a>
  

  
  
    <a href="https://www.linkedin.com/in/maheshkumark" target="_blank"><i class="fa fa-linkedin" aria-hidden="true"></i></a>
  

  
  
    <a href="mailto:maheshk2194@gmail.com" target="_blank"><i class="fa fa-envelope" aria-hidden="true"></i></a>
  

  
  
    <a href="/rss-feed.xml"><i class="fa fa-rss-square" aria-hidden="true"></i></a>
  

  <!-- <div class="post-date"><a href="/menu/about.html">Mahesh Kumar |  by Mahesh Kumar</a></div> -->
  <div class="post-date">Theme Courtesy -<a href="https://github.com/LeNPaul/Lagrange">Lagrange</a></div>
</footer>

  </div>

</body>
</html>
